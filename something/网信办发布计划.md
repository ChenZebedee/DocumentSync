# 网信办发布计划
<!-- TOC -->

- [网信办发布计划](#网信办发布计划)
    - [1. 环境安装](#1-环境安装)
        - [1.1 JAVA 支持](#11-java-支持)
        - [1.2 目录说明](#12-目录说明)
        - [1.3 项目 git 地址](#13-项目-git-地址)
    - [2. canal server 配置 -- 线上 ecs 服务器配置](#2-canal-server-配置----线上-ecs-服务器配置)
        - [2.1 机器需求配置](#21-机器需求配置)
            - [2.1.1 硬件要求](#211-硬件要求)
        - [2.2 数据库配置](#22-数据库配置)
            - [2.2.1 数据库服务配置](#221-数据库服务配置)
            - [2.2.2 账号配置](#222-账号配置)
        - [2.3 下载源码，用 maven 打包](#23-下载源码用-maven-打包)
        - [2.4 配置文件配置](#24-配置文件配置)
        - [2.5 修改启动参数](#25-修改启动参数)
        - [2.6 启动 canal](#26-启动-canal)
    - [3. kafka 安装 -- 线下 84 安装](#3-kafka-安装----线下-84-安装)
    - [4. 同步说明](#4-同步说明)
    - [5. kafka 消费端接口说明 -- 线下 83 运行](#5-kafka-消费端接口说明----线下-83-运行)
    - [特别说明](#特别说明)

<!-- /TOC -->

## 1. 环境安装

### 1.1 JAVA 支持
JAVA 版本: JDK1.8

### 1.2 目录说明
${canal_path} - canal 目录

${consumer_path} - 消费端地址

### 1.3 项目 git 地址
[服务端地址](http://gitlab.mnw-inc.com/data/mz_canal)

[客户端地址](http://gitlab.mnw-inc.com/data/ifcert/tree/master/cert-realtime)


## 2. canal server 配置 -- 线上 ecs 服务器配置

### 2.1 机器需求配置

#### 2.1.1 硬件要求
当处理 200W 左右的数据是，发现cpu占用率机高，最高达 200%，并且会多次宕机，重启即可恢复，并且记录了binlog 的位置偏移量，所以可以继续往下同步

综上，
1. 内存需求大概为 1G
2. 两 C 的 CPU


### 2.2 数据库配置
#### 2.2.1 数据库服务配置
```
[mysqld]
log-bin=mysql-bin #添加这一行就ok
binlog-format=ROW #选择row模式
server_id=1 #配置mysql replaction需要定义，不能和canal的slaveId重复
```

#### 2.2.2 账号配置
```
CREATE USER canal IDENTIFIED BY 'canal';  
GRANT SELECT, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'canal'@'%';
-- GRANT ALL PRIVILEGES ON *.* TO 'canal'@'%' ;
FLUSH PRIVILEGES;
```

### 2.3 下载源码，用 maven 打包
1. 从 github 上拉取源码 ``` git clone http://gitlab.mnw-inc.com/data/mz_canal ```
2. mvn 打包 ``` mvn clean install -Dmaven.test.skip -Denv=release ```

### 2.4 配置文件配置

1. 解压 canal.deployer-1.1.3-SNAPSHOT.tar.gz 压缩文件
    ```
    tar zxf canal.deployer-1.1.3-SNAPSHOT.tar.gz -C ${canal_path}
    ```
2. 修改 ${canal_path}/conf 目录下的 canal.properties 文件
    ```
    1. 修改 canal.serverMode 为 kafka 即 canal.serverMode = kafka
    2. 修改 canal.destinations ,添加 各个数据库的 instance 一个数据库一个名字，以 canal_ 开头后面跟上数据库名
    3. 修改 canal.mq.servers 为线下 kafka 地址 即 canal.mq.servers = 192.168.1.84:9092
    ```
3. 各个 instance 配置
   复制 ${canal_path}/conf 目录下的 template 文件夹并修改为相应的 instance 命名(命名规则 country_canal 加上 schema 名 例：country_canal_test)，每个复制文件夹都对应一个 instance 配置，需对复制文件夹中的 instance.properties (例 ${canal_path}/conf/country_canal_test/instance.properties) 文件进行修改，模版如下：
    ```
    1. canal.instance.master.address -- 需同步的 mysql 库地址 例：
        canal.instance.master.address=rw000001.mysql.rds.aliyuncs.com:3306
    2. canal.instance.dbUsername -- 数据库用户名
        canal.instance.dbUsername=csd
    3. canal.instance.dbPassword -- 数据库密码
        canal.instance.dbPassword=Mnw2018Q2
    4. canal.instance.filter.regex -- 同步规则
        canal.instance.filter.regex=manaowan\\..*,car_loan\\.test*,manaowan_rme\\.aaa -- 可以配置全库，以某出开头的表，以及单张表
    5. canal.mq.topic -- kafka 的 topic 名字
        canal.mq.topic=country_canal_${database_name} -- 以country_canal开头，消费时可以通配
    ```

### 2.5 修改启动参数

修改 ${canal_path}/bin 文件夹下的 startup.sh 文件
```
    1. 将 75 行修改为 JAVA_OPTS="-server -Xms16m -Xmx256m -Xmn128m -XX:SurvivorRatio=8 -XX:PermSize=16m -XX:MaxPermSize=256m -Xss256k -XX:-UseAdaptiveSizePolicy -XX:MaxTenuringThreshold=15 -XX:+DisableExplicitGC -XX:+UseConcMarkSweepGC -XX:+CMSParallelRemarkEnabled -XX:+UseCMSCompactAtFullCollection -XX:+UseFastAccessorMethods -XX:+UseCMSInitiatingOccupancyOnly "
    2. 将 78 行修改为 JAVA_OPTS="-server -Xms16m -Xmx256m -XX:NewSize=256m -XX:MaxNewSize=256m -XX:MaxPermSize=128m "
```

### 2.6 启动 canal

在 ${canal_path}/bin 运行 ``` sh startup.sh ```

## 3. kafka 安装 -- 线下 84 安装
目前在 84 上安装了单机的 kafka，如果需要可以在 83 和 84 搭建一个冗余 kafka 。


## 4. 同步说明
1. 在全量同步前配好表，并启动 server 端服务。
2. 用原来的 shell 同步方案，实现全量同步。
3. 线下脱敏规则位置 ```/home/canal_consumer/docker_run/config/maskInfo```
3. 之后用 curl 开启监听 即：``` curl 192.168.1.83:18888/startKafkaListener ```
4. 如果有新增同步表，只需在配置文件里添加不用重启 server 端服务


## 5. kafka 消费端接口说明 -- 线下 83 运行
1. 脱敏配置 -- 沿用老的规则
2. 开启监听接口 ``` 192.168.1.83:18888/startKafkaListener ```
3. 关闭监听接口 ``` 192.168.1.83:18888/stopKafkaListener ```
4. 身份证处理接口 ``` http://192.168.1.83:18888/getIdCardExtend?idCard=${idCard} ```
    ```
    输入 330327199511061571 输出 
    3303,19951106,1,12db6e99b75537c140ca485ce1a5d3ecc7a4cb19ce5bc5c7931482699361cfde
    ```
5. 更新脱敏规则 ``` 192.168.1.83:18888/updateMaskInfo ``` -- 新增脱敏规则时使用
6. 更新 spring boot 配置文件 ``` curl -X POST http://192.168.1.83:18888/actuator/refresh ``` -- 新增配置文件或修改配置时使用，如新增了 schema 映射关系时就需要更新

## 特别说明

身份证扩展表处理，扩展表放到扩展库中，表名相同。例如：```amp.t_user``` 放入 ```extend.t_user_amp```

字段内容为
| 字段名 | 数据类型 |
| :---|---:|
|原表主键|原表主键数据类型|
|city|VARCHAR(45)|
|birthday|VARCHAR(45)|
|sex|VARCHAR(45)|
|sha256|VARCHAR(256)|