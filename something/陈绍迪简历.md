# 联系方式

- 手机：17826800434
- Email：dishaochen@yahoo.com 
- QQ/微信号：331471867

# 个人信息

 - 陈绍迪/男/1995 
 - 本科/杭州电子科技大学 
 - 工作年限：1年
 - Github：https://github.com/ChenZebedee

 - 期望职位：大数据工程师 大数据开发
 - 期望薪资：税前月薪13k~15k，特别喜欢的公司可例外
 - 期望城市：杭州



# 工作经历

## 杭州玛瑙湾科技有限公标 （ 2018年6月 ~ 至今 ）

### canal 实时同步
#### 技术应用：spring boot +  kafka + canal
我是这个项目的负责人，所有项目流程以及开发都是由我个人历时2个月完成，其中包括阅读 canal 源码，开发消费端，给 canal 服务端添加日志。上线以来，稳定运行，实现实时同步线上数据到本地。其中消费端的开发，通过 kafka 作为消息中间件，开发 kafka 消费端，并添加数据脱敏功能，以及身份证拓展表功能。其中脱敏功能写了一个第三方包，可以后续添加到 canal 服务端上，让数据实现，脱离生产即脱敏的功能。这个项目实施前，数据同步周期为 1 天一次，而项目上线后，可以实现实时同步。感觉从中起码学会了源码阅读，虽然很累，说实话，阿里代码规范也不咋地。

### 大数据基础环境搭建
#### 技术应用：hadoop + hive + hbase + zookeeper + spark + MapReduce
独立负责整个公司大数据环境的搭建、优化与开发，以及 ETL 数据处理。项目现在还在迭代更新。其中最有趣的是协助建模同事进行风控建模，将 30+ 张表的宽表整合，用于数据建模的数据提供。30+ 张表进行分块关联，汇总成一张表，其中，每块都需要 3-4 层关联才能取出数据，这在hive中容易实现，sql join 就可以了，但是在 MR 中，实现就需要进行多层的 MR 嵌套，当然，有可能是我技术水平有限，只能想到这个方法，然后其中有的表根据关联字段会有多条数据，根据建模的同事的要求，要把多条数据转成一条，即根据某一区别字段，将字段内容与其他字段组合作为新的字段名，最后将数据存入 HBase，供建模人员取数，其中包括 HBase 批量查询接口的开发。感觉自己从中更加了解底层的原理，根据原理要实现参数设置，如果数据量过大，那么将无限 oom ，个人思考，以及和同学讨论，想到了各种骚操作来解决 oom。

### 建模数据处理
#### 技术应用：hadoop + hive + hbase
对于同事的上千个字段个宽表处理。举个例子，原数据是4张表，可是需要将字段内容变为新的字段名，而整理，数据处理，数据输出都是我一个人实现的，其中包括，4张表，每两张表的关联内容是怎么样的，以及关联之后，数据内容怎么处理的，存到hbase表之后，我该怎么把数据导出来，以及提供接口给建模人员根据rowkey导出自己想要的数据内容

  
## 北京思特奇 （ 2017年6月 ~ 2018年4月 ）

### 数据比对程序 (2017.11-2018.04)
#### 技术应用：Java + MR + python + shell
通过 ogg 获取到 oracle 数据，以及通过 sqoop 抽 oracle 到 hive， oracle 到 hdfs等，oracle 中的存储过程开发， hive 的外部表测试， hbase 多列簇开发等。以及数据准确性的 MR 开发， shell 开发， python 开发等。作业监控的 jar 开发。其主要目的是为了进行数据保障，如果出问题，还要进行人工检查， 查出问题后,重新导入数据。    


### Mr 开发 2017.10-2018.01
#### 技术应用：hadoop + hbase + zookeeper + MapReduce
1. 因需要将原 tb 环境的数据都导入到新的 Hbase 环境中， 脱离原来的数据环境，放到新的大数据环境中。所以要做初始化，原来直接从数据弄到多列簇表中时，会有漏数丢数的情况发生，还好做了单表的备份，可以直接重单表抽数据到多列簇中，然后就要写 MapReduce，将单表抽到多列簇中，然后还需要写一个对比数据量的 Mr，只要重写一下 RowCounter 类就行了。然后还要写一个全字段比对的 MR。 并每天进行比对。
2. 原先通过 python 脚本连接 hive 对数据进行处理，因计算中需要用到本条数据和下条数据，所以不能用 sql 语句直接执行处理，只能通过 python 获取数据，并进行计算， 但是查询坐标时，会对另一张表进行多次读写，所以速度会比较慢，慢在开链接和关链接，小组商量后，准备进行 mapreduce 开发，直接对文件进行处理，最后再导入 hive 表中。 MapReduce 中写了两个 map 和两个 reduce，因为文件关联的 key 不同所以需要两个 mr 来实现，因为之前 python 的逻辑与流程都是参与开发，已经很清楚了，所以 mr 是我个人独立开发的。最后 mr 开发出来，只需要 10 分钟，就能跑完原来 python 需要半天跑的数据，最后将数据传给前台。进行开发。 

  
  
# 技能清单
以下均为我熟练使用的技能

- 数据库相关：MySQL
- 版本管理、文档和自动化部署工具：Git
- 编程语言：java/shell
- 大数据相关：hadoop/hive/hbase/spark/kafka 

# 自我介绍
我是一个比较喜欢折腾的人，自己在家喜欢玩玩各种东西，比如说星际矿难时，买了一台二手星际魔盒装黑群晖，用于网盘同步，自己电脑也经常在 windows 和 linux 系统之间重复重装，我也乐于助人，如果同事有任何问题，我都会积极帮助，尤其是技术上的问题，但是我更喜欢的是讨论形式的，大家来个头脑风暴，我的不足可以从中得到进步。最近在家里折腾黑苹果，由于周末都有事，所有，驱动并没有进行处理，现在还是处于能上网就万岁的地步

# 致谢
感谢您花时间阅读我的简历，期待能有机会和您共事。
