# 联系方式

- 手机：17826800434
- Email：dishaochen@yahoo.com 
- QQ/微信号：331471867

# 个人信息

 - 陈绍迪/男/1995 
 - 本科/杭州电子科技大学 
 - 工作年限：1年
 - Github：https://github.com/ChenZebedee

 - 期望职位：大数据工程师 大数据开发
 - 期望薪资：税前月薪13k~15k，特别喜欢的公司可例外
 - 期望城市：杭州



# 工作经历

## 杭州玛瑙湾科技有限公标 （ 2018年6月 ~ 至今 ）

### canal 实时同步
#### spring boot +  kafka + canal
我是这个项目的负责人，所有项目流程以及开发都是由我个人历时2个月完成，其中包括阅读 canal 源码，开发消费端，给 canal 服务端添加日志。上线以来，稳定运行，实现实时同步线上数据到本地。其中消费端的开发，通过 kafka 作为消息中间件，开发 kafka 消费端，并添加数据脱敏功能，以及身份证拓展表功能。其中脱敏功能写了一个第三方包，可以后续添加到 canal 服务端上，让数据实现，脱离生产即脱敏的功能。这个项目实施前，数据同步周期为 1 天一次，而项目上线后，可以实现实时同步。感觉从中起码学会了源码阅读，虽然很累，说实话，阿里代码规范也不咋地。

### 大数据基础环境搭建
#### hadoop + hive + hbase + zookeeper + spark + MapReduce
独立负责整个公司大数据环境的搭建、优化与开发，以及 ETL 数据处理。项目现在还在迭代更新。其中最有趣的是协助建模同事进行风控建模，将 30+ 张表的宽表整合，用于数据建模的数据提供。30+ 张表进行分块关联，汇总成一张表，其中，每块都需要 3-4 层关联才能取出数据，这在hive中容易实现，sql join 就可以了，但是在 MR 中，实现就需要进行多层的 MR 嵌套，当然，有可能是我技术水平有限，只能想到这个方法，然后其中有的表根据关联字段会有多条数据，根据建模的同事的要求，要把多条数据转成一条，即根据某一区别字段，将字段内容与其他字段组合作为新的字段名，最后将数据存入 HBase，供建模人员取数，其中包括 HBase 批量查询接口的开发。感觉自己从中更加了解底层的原理，根据原理要实现参数设置，如果数据量过大，那么将无限 oom ，个人思考，以及和同学讨论，想到了各种骚操作来解决 oom。

  
## 北京思特奇 （ 2017年月 ~ 2012年8月 ）

### MNO项目 
我在此项目负责了哪些工作，分别在哪些地方做得出色/和别人不一样/成长快，这个项目中，我最困难的问题是什么，我采取了什么措施，最后结果如何。这个项目中，我最自豪的技术细节是什么，为什么，实施前和实施后的数据对比如何，同事和领导对此的反应如何。


### PQR项目 
我在此项目负责了哪些工作，分别在哪些地方做得出色/和别人不一样/成长快，这个项目中，我最困难的问题是什么，我采取了什么措施，最后结果如何。这个项目中，我最自豪的技术细节是什么，为什么，实施前和实施后的数据对比如何，同事和领导对此的反应如何。


### 其他项目

（每个公司写2~3个核心项目就好了，如果你有非常大量的项目，那么按分类进行合并，每一类选一个典型写出来。其他的一笔带过即可。）
  
  
# 技能清单
以下均为我熟练使用的技能

- 数据库相关：MySQL
- 版本管理、文档和自动化部署工具：Git
- 编程语言：java/shell
- 大数据相关：hadoop/hive/hbase/spark

# 自我介绍
我是一个比较喜欢折腾的人，自己在家喜欢玩玩各种东西，比如说星际矿难时，买了一台二手星际魔盒装黑群晖，用于网盘同步，自己电脑也经常在 windows 和 linux 系统之间重复重装，我也乐于助人，如果同事有任何问题，我都会积极帮助，尤其是技术上的问题，但是我更喜欢的是讨论形式的，大家来个头脑风暴，我的不足可以从中得到进步。

# 致谢
感谢您花时间阅读我的简历，期待能有机会和您共事。
